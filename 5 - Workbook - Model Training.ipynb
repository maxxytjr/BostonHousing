{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPANION WORKBOOK\n",
    "\n",
    "# Model Training\n",
    "\n",
    "To make the most out of this program, we strongly recommend you to:\n",
    "1. First practice writing and implementing all of the code from Coding Section of the online module.\n",
    "2. Then, freely experiment with and explore any interesting or confusing concepts. Simply insert new code cells and then use the help of Google and official documentation.\n",
    "3. Finally, tackle all of the exercises at the end. They will help you tie everything together and **learn in context.**\n",
    "\n",
    "#### <span style=\"color:#555\">MODULE CODE SANDBOX</span>\n",
    "\n",
    "Use this space to practice writing and implementing all of the code from Coding Section of the online module. Insert new code cells as needed, and feel free to write notes to yourself in Markdown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Spending Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Regularized Regression algos\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "\n",
    "# Import Tree Ensemble algos\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1863, 40)\n"
     ]
    }
   ],
   "source": [
    "# Load ABT from Module 3\n",
    "df = pd.read_csv('analytical_base_table.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tx_price</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>lot_size</th>\n",
       "      <th>basement</th>\n",
       "      <th>restaurants</th>\n",
       "      <th>groceries</th>\n",
       "      <th>nightlife</th>\n",
       "      <th>cafes</th>\n",
       "      <th>shopping</th>\n",
       "      <th>arts_entertainment</th>\n",
       "      <th>beauty_spas</th>\n",
       "      <th>active_life</th>\n",
       "      <th>median_age</th>\n",
       "      <th>married</th>\n",
       "      <th>college_grad</th>\n",
       "      <th>property_tax</th>\n",
       "      <th>insurance</th>\n",
       "      <th>median_school</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>two_and_two</th>\n",
       "      <th>recession</th>\n",
       "      <th>property_age</th>\n",
       "      <th>school_score</th>\n",
       "      <th>roof_Asphalt</th>\n",
       "      <th>roof_Composition Shingle</th>\n",
       "      <th>roof_Missing</th>\n",
       "      <th>roof_Others</th>\n",
       "      <th>roof_Shake Shingle</th>\n",
       "      <th>exterior_walls_Brick</th>\n",
       "      <th>exterior_walls_Brick veneer</th>\n",
       "      <th>exterior_walls_Combination</th>\n",
       "      <th>exterior_walls_Metal</th>\n",
       "      <th>exterior_walls_Missing</th>\n",
       "      <th>exterior_walls_Other</th>\n",
       "      <th>exterior_walls_Siding (Alum/Vinyl)</th>\n",
       "      <th>exterior_walls_Wood</th>\n",
       "      <th>property_type_Apartment / Condo / Townhouse</th>\n",
       "      <th>property_type_Single-Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>423010.393451</td>\n",
       "      <td>3.409018</td>\n",
       "      <td>2.564144</td>\n",
       "      <td>2299.173913</td>\n",
       "      <td>12522.044552</td>\n",
       "      <td>0.879227</td>\n",
       "      <td>40.352657</td>\n",
       "      <td>4.515835</td>\n",
       "      <td>5.100913</td>\n",
       "      <td>5.348900</td>\n",
       "      <td>40.945786</td>\n",
       "      <td>3.406871</td>\n",
       "      <td>23.464305</td>\n",
       "      <td>15.896404</td>\n",
       "      <td>38.604402</td>\n",
       "      <td>69.070853</td>\n",
       "      <td>65.047236</td>\n",
       "      <td>461.369834</td>\n",
       "      <td>138.816425</td>\n",
       "      <td>6.495706</td>\n",
       "      <td>2.791734</td>\n",
       "      <td>0.095545</td>\n",
       "      <td>0.263553</td>\n",
       "      <td>24.397209</td>\n",
       "      <td>17.982823</td>\n",
       "      <td>0.073001</td>\n",
       "      <td>0.644659</td>\n",
       "      <td>0.188943</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>0.366076</td>\n",
       "      <td>0.025765</td>\n",
       "      <td>0.056897</td>\n",
       "      <td>0.064412</td>\n",
       "      <td>0.119163</td>\n",
       "      <td>0.035963</td>\n",
       "      <td>0.266237</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.430488</td>\n",
       "      <td>0.569512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>151764.257544</td>\n",
       "      <td>1.065101</td>\n",
       "      <td>0.928741</td>\n",
       "      <td>1298.029915</td>\n",
       "      <td>35040.992371</td>\n",
       "      <td>0.325951</td>\n",
       "      <td>47.038157</td>\n",
       "      <td>4.501180</td>\n",
       "      <td>8.500743</td>\n",
       "      <td>7.566931</td>\n",
       "      <td>53.717473</td>\n",
       "      <td>4.705711</td>\n",
       "      <td>25.837376</td>\n",
       "      <td>17.724606</td>\n",
       "      <td>6.643582</td>\n",
       "      <td>19.679230</td>\n",
       "      <td>16.904131</td>\n",
       "      <td>222.484352</td>\n",
       "      <td>70.250523</td>\n",
       "      <td>1.992058</td>\n",
       "      <td>0.507300</td>\n",
       "      <td>0.294045</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>21.087996</td>\n",
       "      <td>6.465535</td>\n",
       "      <td>0.260207</td>\n",
       "      <td>0.478745</td>\n",
       "      <td>0.391568</td>\n",
       "      <td>0.240726</td>\n",
       "      <td>0.175165</td>\n",
       "      <td>0.481860</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>0.231709</td>\n",
       "      <td>0.245552</td>\n",
       "      <td>0.324067</td>\n",
       "      <td>0.186249</td>\n",
       "      <td>0.442108</td>\n",
       "      <td>0.247447</td>\n",
       "      <td>0.495278</td>\n",
       "      <td>0.495278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>300000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1342.500000</td>\n",
       "      <td>1540.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>392000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>5846.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>423.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>525000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2951.000000</td>\n",
       "      <td>11325.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>800000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7842.000000</td>\n",
       "      <td>436471.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>4508.000000</td>\n",
       "      <td>1374.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tx_price         beds        baths         sqft       lot_size  \\\n",
       "count    1863.000000  1863.000000  1863.000000  1863.000000    1863.000000   \n",
       "mean   423010.393451     3.409018     2.564144  2299.173913   12522.044552   \n",
       "std    151764.257544     1.065101     0.928741  1298.029915   35040.992371   \n",
       "min    200000.000000     1.000000     1.000000   500.000000       0.000000   \n",
       "25%    300000.000000     3.000000     2.000000  1342.500000    1540.000000   \n",
       "50%    392000.000000     3.000000     3.000000  1900.000000    5846.000000   \n",
       "75%    525000.000000     4.000000     3.000000  2951.000000   11325.000000   \n",
       "max    800000.000000     5.000000     6.000000  7842.000000  436471.000000   \n",
       "\n",
       "          basement  restaurants    groceries    nightlife        cafes  \\\n",
       "count  1863.000000  1863.000000  1863.000000  1863.000000  1863.000000   \n",
       "mean      0.879227    40.352657     4.515835     5.100913     5.348900   \n",
       "std       0.325951    47.038157     4.501180     8.500743     7.566931   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     7.000000     1.000000     0.000000     0.000000   \n",
       "50%       1.000000    23.000000     3.000000     2.000000     3.000000   \n",
       "75%       1.000000    58.000000     7.000000     6.000000     6.500000   \n",
       "max       1.000000   266.000000    24.000000    54.000000    47.000000   \n",
       "\n",
       "          shopping  arts_entertainment  beauty_spas  active_life   median_age  \\\n",
       "count  1863.000000         1863.000000  1863.000000  1863.000000  1863.000000   \n",
       "mean     40.945786            3.406871    23.464305    15.896404    38.604402   \n",
       "std      53.717473            4.705711    25.837376    17.724606     6.643582   \n",
       "min       0.000000            0.000000     0.000000     0.000000    22.000000   \n",
       "25%       6.500000            0.000000     4.000000     4.500000    33.000000   \n",
       "50%      22.000000            2.000000    15.000000    10.000000    38.000000   \n",
       "75%      51.000000            5.000000    35.500000    21.000000    43.000000   \n",
       "max     340.000000           35.000000   177.000000    94.000000    69.000000   \n",
       "\n",
       "           married  college_grad  property_tax    insurance  median_school  \\\n",
       "count  1863.000000   1863.000000   1863.000000  1863.000000    1863.000000   \n",
       "mean     69.070853     65.047236    461.369834   138.816425       6.495706   \n",
       "std      19.679230     16.904131    222.484352    70.250523       1.992058   \n",
       "min      11.000000      5.000000     88.000000    30.000000       1.000000   \n",
       "25%      58.000000     53.000000    319.000000    94.000000       5.000000   \n",
       "50%      73.000000     66.000000    423.000000   124.000000       7.000000   \n",
       "75%      84.000000     78.000000    564.000000   168.000000       8.000000   \n",
       "max     100.000000    100.000000   4508.000000  1374.000000      10.000000   \n",
       "\n",
       "       num_schools  two_and_two    recession  property_age  school_score  \\\n",
       "count  1863.000000  1863.000000  1863.000000   1863.000000   1863.000000   \n",
       "mean      2.791734     0.095545     0.263553     24.397209     17.982823   \n",
       "std       0.507300     0.294045     0.440678     21.087996      6.465535   \n",
       "min       1.000000     0.000000     0.000000      0.000000      3.000000   \n",
       "25%       3.000000     0.000000     0.000000      6.000000     12.000000   \n",
       "50%       3.000000     0.000000     0.000000     21.000000     18.000000   \n",
       "75%       3.000000     0.000000     1.000000     38.000000     24.000000   \n",
       "max       4.000000     1.000000     1.000000    114.000000     30.000000   \n",
       "\n",
       "       roof_Asphalt  roof_Composition Shingle  roof_Missing  roof_Others  \\\n",
       "count   1863.000000               1863.000000   1863.000000  1863.000000   \n",
       "mean       0.073001                  0.644659      0.188943     0.061728   \n",
       "std        0.260207                  0.478745      0.391568     0.240726   \n",
       "min        0.000000                  0.000000      0.000000     0.000000   \n",
       "25%        0.000000                  0.000000      0.000000     0.000000   \n",
       "50%        0.000000                  1.000000      0.000000     0.000000   \n",
       "75%        0.000000                  1.000000      0.000000     0.000000   \n",
       "max        1.000000                  1.000000      1.000000     1.000000   \n",
       "\n",
       "       roof_Shake Shingle  exterior_walls_Brick  exterior_walls_Brick veneer  \\\n",
       "count         1863.000000           1863.000000                  1863.000000   \n",
       "mean             0.031669              0.366076                     0.025765   \n",
       "std              0.175165              0.481860                     0.158476   \n",
       "min              0.000000              0.000000                     0.000000   \n",
       "25%              0.000000              0.000000                     0.000000   \n",
       "50%              0.000000              0.000000                     0.000000   \n",
       "75%              0.000000              1.000000                     0.000000   \n",
       "max              1.000000              1.000000                     1.000000   \n",
       "\n",
       "       exterior_walls_Combination  exterior_walls_Metal  \\\n",
       "count                 1863.000000           1863.000000   \n",
       "mean                     0.056897              0.064412   \n",
       "std                      0.231709              0.245552   \n",
       "min                      0.000000              0.000000   \n",
       "25%                      0.000000              0.000000   \n",
       "50%                      0.000000              0.000000   \n",
       "75%                      0.000000              0.000000   \n",
       "max                      1.000000              1.000000   \n",
       "\n",
       "       exterior_walls_Missing  exterior_walls_Other  \\\n",
       "count             1863.000000           1863.000000   \n",
       "mean                 0.119163              0.035963   \n",
       "std                  0.324067              0.186249   \n",
       "min                  0.000000              0.000000   \n",
       "25%                  0.000000              0.000000   \n",
       "50%                  0.000000              0.000000   \n",
       "75%                  0.000000              0.000000   \n",
       "max                  1.000000              1.000000   \n",
       "\n",
       "       exterior_walls_Siding (Alum/Vinyl)  exterior_walls_Wood  \\\n",
       "count                         1863.000000          1863.000000   \n",
       "mean                             0.266237             0.065486   \n",
       "std                              0.442108             0.247447   \n",
       "min                              0.000000             0.000000   \n",
       "25%                              0.000000             0.000000   \n",
       "50%                              0.000000             0.000000   \n",
       "75%                              1.000000             0.000000   \n",
       "max                              1.000000             1.000000   \n",
       "\n",
       "       property_type_Apartment / Condo / Townhouse  \\\n",
       "count                                  1863.000000   \n",
       "mean                                      0.430488   \n",
       "std                                       0.495278   \n",
       "min                                       0.000000   \n",
       "25%                                       0.000000   \n",
       "50%                                       0.000000   \n",
       "75%                                       1.000000   \n",
       "max                                       1.000000   \n",
       "\n",
       "       property_type_Single-Family  \n",
       "count                  1863.000000  \n",
       "mean                      0.569512  \n",
       "std                       0.495278  \n",
       "min                       0.000000  \n",
       "25%                       0.000000  \n",
       "50%                       1.000000  \n",
       "75%                       1.000000  \n",
       "max                       1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate object for target variable\n",
    "y = df.tx_price\n",
    "X = df.drop('tx_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 1490 373 373\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(y_train), len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review: Cross-validation**\n",
    "\n",
    "CV is a method for preventing overfitting, and getting a reliable estimate of model performance using only your training data. It breaks your training data into 10 equal parts (a.k.a. folds), creating 10 miniature train/test partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Preprocessing & Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we might want to process our data further before feeding it into our algorithms. For example, transforming or scaling our features.\n",
    "\n",
    "Such preprocessing steps should be done **inside a cross-validation loop**.\n",
    "\n",
    "**Standardization is one of the most common preprocessing technique in machine learning.**\n",
    "\n",
    "It transforms all of your features **to the same scale** by subtracting means and then dividing by standard deviations. \n",
    "\n",
    "This makes the values **centered around 0, with unit variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing parameters\n",
    "\n",
    "For standardization, these will be the **means and std** of each feature.\n",
    "\n",
    "If we wish to preprocess unseen data (eg our test set), we will need to use the SAME preprocessing parameters that we learned from the training set. \n",
    "\n",
    "So, X_test = (X_test - X_train.mean()) / X_train.std()\n",
    "\n",
    "When done correctly, your transformed X_test_new is not guaranteed to have mean 0 and variance 1, although it will often be close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here's how the new 10-fold cross-validation process would look when it includes preprocessing:\n",
    "1. Split your data into 10 equal folds.\n",
    "2. **Preprocess 9 training folds, learning the preprocessing parameters.**\n",
    "3. Train your model on the same 9 folds.\n",
    "4. **Preprocess the hold-out fold using the same preprocessing parameters from step (2).**\n",
    "5. Evaluate your model on the same hold-out fold.\n",
    "6. Perform steps (2) - (5) 10 times, each time holding out a different fold.\n",
    "7. Average the performance across all 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('lasso',\n",
       "                 Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=1000, normalize=False, positive=False,\n",
       "                       precompute=False, random_state=123, selection='cyclic',\n",
       "                       tol=0.0001, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline with standardization and Lasso regression\n",
    "make_pipeline(StandardScaler(), Lasso(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It is better to store all the pipelines that we want to test in a dictionary for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline dictionary\n",
    "pipelines = {\n",
    "    'lasso': make_pipeline(StandardScaler(), Lasso(random_state=123)),\n",
    "    'ridge': make_pipeline(StandardScaler(), Ridge(random_state=123))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasso': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('lasso',\n",
       "                  Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                        max_iter=1000, normalize=False, positive=False,\n",
       "                        precompute=False, random_state=123, selection='cyclic',\n",
       "                        tol=0.0001, warm_start=False))],\n",
       "          verbose=False), 'ridge': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('ridge',\n",
       "                  Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                        max_iter=None, normalize=False, random_state=123,\n",
       "                        solver='auto', tol=0.001))],\n",
       "          verbose=False), 'enet': Pipeline(memory=None,\n",
       "          steps=[('standardscaler',\n",
       "                  StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                 ('elasticnet',\n",
       "                  ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                             positive=False, precompute=False, random_state=123,\n",
       "                             selection='cyclic', tol=0.0001,\n",
       "                             warm_start=False))],\n",
       "          verbose=False)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a pipeline to existing pipelines dictionary\n",
    "pipelines['enet'] = make_pipeline(StandardScaler(), ElasticNet(random_state=123))\n",
    "\n",
    "pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters express \"higher-level\" structural information about modeling algorithms.\n",
    "\n",
    "1. e.g. strength of the penalty used in regularized regression\n",
    "2. e.g. the number of trees to include in a random forest\n",
    "3. They are set before training the model because they cannot be learned directly from the training data.\n",
    "4. The key distinction is that model parameters can be learned directly from the training data while hyperparameters cannot!\n",
    "\n",
    "**We usually tune hyperparameters in the cross-validation loop.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('lasso', Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "         normalize=False, positive=False, precompute=False, random_state=123,\n",
       "         selection='cyclic', tol=0.0001, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'lasso': Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "       normalize=False, positive=False, precompute=False, random_state=123,\n",
       "       selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'lasso__alpha': 1.0,\n",
       " 'lasso__copy_X': True,\n",
       " 'lasso__fit_intercept': True,\n",
       " 'lasso__max_iter': 1000,\n",
       " 'lasso__normalize': False,\n",
       " 'lasso__positive': False,\n",
       " 'lasso__precompute': False,\n",
       " 'lasso__random_state': 123,\n",
       " 'lasso__selection': 'cyclic',\n",
       " 'lasso__tol': 0.0001,\n",
       " 'lasso__warm_start': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list hyperparameters that we can tune in the Lasso pipeline\n",
    "pipelines['lasso'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('elasticnet',\n",
       "   ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "              max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "              random_state=123, selection='cyclic', tol=0.0001, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'elasticnet': ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "            max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "            random_state=123, selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'elasticnet__alpha': 1.0,\n",
       " 'elasticnet__copy_X': True,\n",
       " 'elasticnet__fit_intercept': True,\n",
       " 'elasticnet__l1_ratio': 0.5,\n",
       " 'elasticnet__max_iter': 1000,\n",
       " 'elasticnet__normalize': False,\n",
       " 'elasticnet__positive': False,\n",
       " 'elasticnet__precompute': False,\n",
       " 'elasticnet__random_state': 123,\n",
       " 'elasticnet__selection': 'cyclic',\n",
       " 'elasticnet__tol': 0.0001,\n",
       " 'elasticnet__warm_start': False}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['enet'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### All of the keys that start with 'lasso_' are hyperparameters.\n",
    "\n",
    "###### For Lasso and Ridge regularized regression, the most impactful hyperparameter is the strength of the penalty (alpha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of hyperparameters (hyperparameter grid) for each pipeline\n",
    "# When tuning a model pipeline, you must preprend the algorithm name and two underscores\n",
    "lasso_hyperparameters = {\n",
    "    'lasso__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "ridge_hyperparameters = {\n",
    "    'ridge__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10] \n",
    "}\n",
    "\n",
    "enet_hyperparameters = {\n",
    "    'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
    "    'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'lasso': lasso_hyperparameters,\n",
    "    'ridge': ridge_hyperparameters,\n",
    "    'enet': enet_hyperparameters\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we are ready to tune our models with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso model has been fitted.\n",
      "ridge model has been fitted.\n",
      "enet model has been fitted.\n"
     ]
    }
   ],
   "source": [
    "# train 10-fold cv, specifying n_jobs=-1 to train in parallel across the max number of cores in the computer\n",
    "\n",
    "fitted_models = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # store current model in fitted_models dictionary\n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    print(f'{name} model has been fitted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time to evaluate our models and pick the best one.\n",
    "\n",
    "One of the first ways to evaluate your models is by looking at their **cross-validated performance** on the training set. These scores are called the **holdout R2 scores**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso 0.30862750804200023\n",
      "ridge 0.31661115859856476\n",
      "enet 0.3428746287380323\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For regression problems, the default scoring metric is R2.**\n",
    "\n",
    "Because holdout R2 is the average R2 from the holdout folds during cross-validation, **higher is almost always better**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate r2 on the test set\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another metric that would be especially useful for this problem is Mean Absolute Error, or MAE.**\n",
    "\n",
    "MAE is the absolute difference between the predicted target variable and the actual target variable in our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.4088862501934907\n",
      "MAE score: 85035.54212406879\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "lasso_pred = fitted_models['lasso'].predict(X_test)\n",
    "# Calculate and print R^2 and MAE. [actual, pred]\n",
    "print(\"R^2 score: {}\".format(r2_score(y_test, lasso_pred)))\n",
    "print(\"MAE score: {}\".format(mean_absolute_error(y_test, lasso_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#555\">EXERCISES</span>\n",
    "\n",
    "Complete each of the following exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.1 - Coding Section Checkpoint</span>\n",
    "\n",
    "Before moving on, it's imperative that you've been following along the online Coding Section of this module. Those are core to each module and often contain **mission-critical code**, which means that the following modules REQUIRE you to have run that code.\n",
    "\n",
    "#### A.) First, confirm that you've successfully separated the data into a training set and a test set.\n",
    "* How many observations are in the training set?\n",
    "* How many observations are in the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n",
      "373\n",
      "1490\n",
      "373\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, display the Ridge regression pipeline object saved in the pipelines dictionary.\n",
    "* What steps are in the pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('ridge',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=123,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['ridge']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('ridge', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "   normalize=False, random_state=123, solver='auto', tol=0.001))]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, display the <code>l1_ratio</code> hyperparameter values to try for your Elastic-Net algorithm.\n",
    "* **Tip:** Remember the naming convention within pipelines (need the named step first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elasticnet__alpha': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10],\n",
       " 'elasticnet__l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters['enet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1, 0.3, 0.5, 0.7, 0.9]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters['enet']['elasticnet__l1_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.2 - Sklearn's Standard Scaler</span>\n",
    "\n",
    "Whenever you preprocess your dataset, it's important to use the same **preprocessing parameters** on new data as you used on the training set. So if you standardize your dataset, you must also standardize the test set with the same means and standard deviations from the training set.\n",
    "\n",
    "#### A.) First, display the standardization parameters for the <code>beds</code> feature in the training set (<code>X_train</code>).\n",
    "* You'll need the mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 3.434228187919463\n",
      "Standard Deviation: 1.0729140858452628\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: {X_train['beds'].mean()}\")\n",
    "print(f\"Standard Deviation: {X_train['beds'].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0729140858452646\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TRAINING set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five_beds = (X_train['beds'].head() - X_train['beds'].mean()) / X_train['beds'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1689    1.459364\n",
       "1531    0.527323\n",
       "668    -0.404719\n",
       "1740    1.459364\n",
       "117    -1.336760\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_five_beds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "1689    1.459\n",
    "1531    0.527\n",
    "668    -0.405\n",
    "1740    1.459\n",
    "117    -1.337\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, based on your parameters from part (A), manually standardize the first 5 observations from the <code>beds</code> feature in the TEST set. Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266   -1.336760\n",
       "790   -0.404719\n",
       "222   -1.336760\n",
       "220   -1.336760\n",
       "920   -0.404719\n",
       "Name: beds, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_five_beds_test = (X_test['beds'].head() - X_train['beds'].mean()) / X_train['beds'].std()\n",
    "first_five_beds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "266   -1.337\n",
    "790   -0.405\n",
    "222   -1.337\n",
    "220   -1.337\n",
    "920   -0.405\n",
    "Name: beds, dtype: float64\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Scikit-Learn's <code>StandardScaler()</code> class allows you to save those preprocessing parameters learned from the training set.\n",
    "1. First, initialize and instance of the scaler class.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "scaler = StandardScaler()\n",
    "</pre>\n",
    "\n",
    "2. Then, call the <code>.fit()</code> while passing in the **entire** training set (all of the features, not just beds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.) Now you can display the preprocessing parameters directly from the <code>scaler</code> object.\n",
    "* It will save the means from all features as an array in <code>.mean_</code>.\n",
    "* It will save the standard deviations from all features as an array in <code>.scale_</code>.\n",
    "* **Tip:** The <code>beds</code> feature should be the first one.\n",
    "* Check for yourself that the preprocessing parameters are the same as the ones you found in part (A)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.43422819e+00, 2.57919463e+00, 2.32278523e+03, 1.27466597e+04,\n",
       "       8.78523490e-01, 3.94959732e+01, 4.38859060e+00, 5.00469799e+00,\n",
       "       5.18590604e+00, 3.95610738e+01, 3.36174497e+00, 2.29093960e+01,\n",
       "       1.57704698e+01, 3.85087248e+01, 6.94711409e+01, 6.50127517e+01,\n",
       "       4.64265772e+02, 1.39610067e+02, 6.51006711e+00, 2.77919463e+00,\n",
       "       9.26174497e-02, 2.65771812e-01, 2.43436242e+01, 1.79402685e+01,\n",
       "       7.31543624e-02, 6.43624161e-01, 1.89261745e-01, 6.04026846e-02,\n",
       "       3.35570470e-02, 3.59731544e-01, 2.41610738e-02, 5.90604027e-02,\n",
       "       6.57718121e-02, 1.19463087e-01, 3.75838926e-02, 2.68456376e-01,\n",
       "       6.57718121e-02, 4.19463087e-01, 5.80536913e-01])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Mean: 3.434228187919463\n",
    "Standard Deviation: 1.0725539871320342\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F.) Next, use the <code>scaler</code> object to <code>.transform()</code> your test set and save it as <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when you use <code>scaler</code> to transform a dataset, it returns a NumPy array and NOT a Pandas DataFrame.\n",
    "\n",
    "#### G.) Confirm this for yourself. Display the class and shape of <code>X_test_new</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 39)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'numpy.ndarray'&gt;\n",
    "(373, 39)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H.) Finally, display the first 5 transformed values for the <code>beds</code> feature.\n",
    "* Because <code>X_test_new</code> is a NumPy array, you won't be able to just call <code>.beds</code> like with Pandas DataFrames. If you try that, you'll get the error:\n",
    "\n",
    "<pre>\n",
    "<span style=\"color:crimson\">AttributeError:</span> 'numpy.ndarray' object has no attribute 'beds'\n",
    "</pre>\n",
    "\n",
    "* Instead, you'll need to index the NumPy array to get the **first 5 rows** from the **first column**. (This is just meant as a refresher and a bit of practice.)\n",
    "* Confirm that the values are the same as the ones you found in part (C) manually. Note that the rounding/precision may be slightly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.33720839, -0.40485439, -1.33720839, -1.33720839, -0.40485439])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_new[:5, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "[-1.33720839 -0.40485439 -1.33720839 -1.33720839 -0.40485439]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.3 - Tree Pipelines</span>\n",
    "\n",
    "In the Coding Section, we created a pipeline dictionary with model pipelines for Lasso, Ridge, and Elastic-Net regressions. In this exercise, let's add pipelines for tree ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) Add pipelines for <code style=\"color:SteelBlue\">RandomForestRegressor</code> and <code style=\"color:SteelBlue\">GradientBoostingRegressor</code> to your pipeline dictionary.\n",
    "* Name them <code style=\"color:crimson\">'rf'</code> for random forest and <code style=\"color:crimson\">'gb'</code> for gradient boosted tree.\n",
    "* Both pipelines should standardize the data first.\n",
    "* For both, set <code style=\"color:steelblue\">random_state=<span style=\"color:crimson\">123</span></code> to ensure replicable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines['rf'] = make_pipeline(StandardScaler(), RandomForestRegressor(random_state=123))\n",
    "pipelines['gb'] = make_pipeline(StandardScaler(), GradientBoostingRegressor(random_state=123))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Just as a quick sanity check, display the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                       criterion='mse', max_depth=None,\n",
       "                                       max_features='auto', max_leaf_nodes=None,\n",
       "                                       max_samples=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=100, n_jobs=None,\n",
       "                                       oob_score=False, random_state=123,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['rf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) As another quick sanity check, display the class for the pipeline object for your random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pipelines['rf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "&lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's check that all of the model pipelines are of the correct type. For each item in your <code>pipelines</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.pipeline.Pipeline'>\n",
      "ridge <class 'sklearn.pipeline.Pipeline'>\n",
      "enet <class 'sklearn.pipeline.Pipeline'>\n",
      "rf <class 'sklearn.pipeline.Pipeline'>\n",
      "gb <class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "for name, pipeline in pipelines.items():\n",
    "    print(name, type(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "ridge &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "enet &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "rf &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "gb &lt;class 'sklearn.pipeline.Pipeline'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.4 - Hyperparameter Grids</span>\n",
    "\n",
    "In the Coding Section, we declared hyperparameter grids for our regularized regression algorithms: Lasso, Ridge, and Elastic-Net. Next, let's do the same for our tree ensembles.\n",
    "\n",
    "\n",
    "#### Let's start by declaring the hyperparameter grid for our random forest.\n",
    "\n",
    "The first one we'll tune is <code style=\"color:steelblue; font-weight:bold\">n_estimators</code>.\n",
    "* This is the number of decision trees to include in the random forest.\n",
    "* Usually, more is better.\n",
    "* The default value is 10, which is usually too few.\n",
    "* Let's try 100 and 200.\n",
    "\n",
    "The second one we'll tune is <code style=\"color:steelblue; font-weight:bold\">max_features</code>.\n",
    "* This controls the number of features each tree is allowed to choose from.\n",
    "* It's what allows your random forest to perform feature selection.\n",
    "* The default value is <code style=\"color:crimson\">'auto'</code>, which sets <code style=\"color:steelblue\">max_features = n_features</code>.\n",
    "* Let's also try <code style=\"color:crimson\">'sqrt'</code>, which sets <code style=\"color:steelblue\">max_features = sqrt(n_features)</code>\n",
    "* And <code style=\"color:crimson\">0.33</code>, which sets <code style=\"color:steelblue\">max_features = 0.33 * n_features</code>\n",
    "\n",
    "#### A.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">RandomForestRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">rf_hyperparameters</code>\n",
    "\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'randomforestregressor\\__max_features'</span>: ['auto', 'sqrt', 0.33]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('randomforestregressor',\n",
       "   RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                         max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                         max_samples=None, min_impurity_decrease=0.0,\n",
       "                         min_impurity_split=None, min_samples_leaf=1,\n",
       "                         min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                         n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                         random_state=123, verbose=0, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'randomforestregressor': RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       max_samples=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                       n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                       random_state=123, verbose=0, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'randomforestregressor__bootstrap': True,\n",
       " 'randomforestregressor__ccp_alpha': 0.0,\n",
       " 'randomforestregressor__criterion': 'mse',\n",
       " 'randomforestregressor__max_depth': None,\n",
       " 'randomforestregressor__max_features': 'auto',\n",
       " 'randomforestregressor__max_leaf_nodes': None,\n",
       " 'randomforestregressor__max_samples': None,\n",
       " 'randomforestregressor__min_impurity_decrease': 0.0,\n",
       " 'randomforestregressor__min_impurity_split': None,\n",
       " 'randomforestregressor__min_samples_leaf': 1,\n",
       " 'randomforestregressor__min_samples_split': 2,\n",
       " 'randomforestregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'randomforestregressor__n_estimators': 100,\n",
       " 'randomforestregressor__n_jobs': None,\n",
       " 'randomforestregressor__oob_score': False,\n",
       " 'randomforestregressor__random_state': 123,\n",
       " 'randomforestregressor__verbose': 0,\n",
       " 'randomforestregressor__warm_start': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['rf'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters['rf'] = {\n",
    "    'randomforestregressor__n_estimators': [100,200],\n",
    "    'randomforestregressor__max_features': ['auto', 'sqrt', 0.33]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's declare settings to try for our boosted tree.\n",
    "\n",
    "#### B.) Declare a hyperparameter grid for <code style=\"color:SteelBlue\">GradientBoostingRegressor</code>.\n",
    "* Name it <code style=\"color:steelblue\">gb_hyperparameters</code>.\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__n_estimators'</span>: [100, 200]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__learning_rate'</span>: [0.05, 0.1, 0.2]</code>\n",
    "* Set <code style=\"color:steelblue\"><span style=\"color:crimson\">'gradientboostingregressor\\__max_depth'</span>: [1, 3, 5]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('standardscaler',\n",
       "   StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "  ('gradientboostingregressor',\n",
       "   GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                             init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=123, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0, warm_start=False))],\n",
       " 'verbose': False,\n",
       " 'standardscaler': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       " 'gradientboostingregressor': GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                           init=None, learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=123, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0, warm_start=False),\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'gradientboostingregressor__alpha': 0.9,\n",
       " 'gradientboostingregressor__ccp_alpha': 0.0,\n",
       " 'gradientboostingregressor__criterion': 'friedman_mse',\n",
       " 'gradientboostingregressor__init': None,\n",
       " 'gradientboostingregressor__learning_rate': 0.1,\n",
       " 'gradientboostingregressor__loss': 'ls',\n",
       " 'gradientboostingregressor__max_depth': 3,\n",
       " 'gradientboostingregressor__max_features': None,\n",
       " 'gradientboostingregressor__max_leaf_nodes': None,\n",
       " 'gradientboostingregressor__min_impurity_decrease': 0.0,\n",
       " 'gradientboostingregressor__min_impurity_split': None,\n",
       " 'gradientboostingregressor__min_samples_leaf': 1,\n",
       " 'gradientboostingregressor__min_samples_split': 2,\n",
       " 'gradientboostingregressor__min_weight_fraction_leaf': 0.0,\n",
       " 'gradientboostingregressor__n_estimators': 100,\n",
       " 'gradientboostingregressor__n_iter_no_change': None,\n",
       " 'gradientboostingregressor__presort': 'deprecated',\n",
       " 'gradientboostingregressor__random_state': 123,\n",
       " 'gradientboostingregressor__subsample': 1.0,\n",
       " 'gradientboostingregressor__tol': 0.0001,\n",
       " 'gradientboostingregressor__validation_fraction': 0.1,\n",
       " 'gradientboostingregressor__verbose': 0,\n",
       " 'gradientboostingregressor__warm_start': False}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines['gb'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters['gb'] = {\n",
    "    'gradientboostingregressor__n_estimators': [100, 200],\n",
    "    'gradientboostingregressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "    'gradientboostingregressor__max_depth': [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our hyperparameters declared, let's store them in a dictionary for ease of access.\n",
    "\n",
    "#### C.) Create a <code style=\"color:steelblue\">hyperparameters</code> dictionary.\n",
    "* Use the same keys as in the <code style=\"color:steelblue\">pipelines</code> dictionary.\n",
    "    * If you forgot what those keys were, you can insert a new code cell and call <code style=\"color:steelblue\">pipelines.keys()</code> for a reminder.\n",
    "* Set the values to the corresponding **hyperparameter grids** we've been declaring throughout this module.\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'rf'</span> : rf_hyperparameters</code>\n",
    "    * e.g. <code style=\"color:steelblue\"><span style=\"color:crimson\">'lasso'</span> : lasso_hyperparameters</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lasso', 'ridge', 'enet', 'gb', 'rf'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparameters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'dict'>\n",
      "ridge <class 'dict'>\n",
      "enet <class 'dict'>\n",
      "gb <class 'dict'>\n",
      "rf <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "for name, hyperparameter in hyperparameters.items():\n",
    "    print(name, type(hyperparameter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, run this code to check that <code style=\"color:steelblue\">hyperparameters</code> is set up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet was found in hyperparameters, and it is a grid.\n",
      "gb was found in hyperparameters, and it is a grid.\n",
      "ridge was found in hyperparameters, and it is a grid.\n",
      "rf was found in hyperparameters, and it is a grid.\n",
      "lasso was found in hyperparameters, and it is a grid.\n"
     ]
    }
   ],
   "source": [
    "for key in ['enet', 'gb', 'ridge', 'rf', 'lasso']:\n",
    "    if key in hyperparameters:\n",
    "        if type(hyperparameters[key]) is dict:\n",
    "            print( key, 'was found in hyperparameters, and it is a grid.' )\n",
    "        else:\n",
    "            print( key, 'was found in hyperparameters, but it is not a grid.' )\n",
    "    else:\n",
    "        print( key, 'was not found in hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "enet was found in hyperparameters, and it is a grid.\n",
    "gb was found in hyperparameters, and it is a grid.\n",
    "ridge was found in hyperparameters, and it is a grid.\n",
    "rf was found in hyperparameters, and it is a grid.\n",
    "lasso was found in hyperparameters, and it is a grid.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.5 - Model Dictionaries</span>\n",
    "\n",
    "Similar to how we created dictionaries for our pipelines and hyperparameter grids, we can do the same for our fitted models. Obviously, there are other valid ways to organize your code and models, but this is a simple and practical way that does the job. By the end of the script, you'll have various dictionary objects that can each be accessed by the same consistent keys.\n",
    "\n",
    "#### A.) Create a dictionary of models named <code style=\"color:SteelBlue\">fitted_models</code> to store models that have been tuned using cross-validation.\n",
    "* The keys should be the same as those in the <code style=\"color:SteelBlue\">pipelines</code> and <code style=\"color:SteelBlue\">hyperparameters</code> dictionaries. \n",
    "* The values should be <code style=\"color:steelblue\">GridSearchCV</code> objects that have been fitted to <code style=\"color:steelblue\">X_train</code> and <code style=\"color:steelblue\">y_train</code>.\n",
    "* After fitting each model, print <code style=\"color:crimson\">'{name} has been fitted.'</code> just to track the progress.\n",
    "* **Tip:** We've started you off with some code.\n",
    "\n",
    "This step can take a few minutes, so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "fitted_models = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyperparameters[name], cv=10, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    fitted_models[name] = model\n",
    "    \n",
    "    print(f\"{name} has been fitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Check that the models are of the correct type. For each item in your <code>fitted_models</code> dictionary, display its key and the class of its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "ridge <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "enet <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "rf <class 'sklearn.model_selection._search.GridSearchCV'>\n",
      "gb <class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(name, type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "ridge &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "enet &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "rf &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "gb &lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Finally, run this code to check that the models have been fitted correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso has been fitted.\n",
      "ridge has been fitted.\n",
      "enet has been fitted.\n",
      "rf has been fitted.\n",
      "gb has been fitted.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "for name, model in fitted_models.items():\n",
    "    try:\n",
    "        pred = model.predict(X_test)\n",
    "        print(name, 'has been fitted.')\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso has been fitted.\n",
    "ridge has been fitted.\n",
    "enet has been fitted.\n",
    "rf has been fitted.\n",
    "gb has been fitted.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.6 - Model Selection</span>\n",
    "\n",
    "In the Coding Section, we displayed performance metrics for a sample Lasso regression model. Now, let's do the same thing for all of our models, including our tree ensembles and then pick the final winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A.) First, display the cross-validated training performance for each model in <code style=\"color:SteelBlue\">fitted_models</code> ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso: 0.30862750804200023\n",
      "ridge: 0.31661115859856476\n",
      "enet: 0.3428746287380323\n",
      "rf: 0.4813165126237962\n",
      "gb: 0.4876362055706826\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    print(f\"{name}: {model.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "lasso 0.30862751105084013\n",
    "ridge 0.3166111585985649\n",
    "enet 0.34285741369864786\n",
    "rf 0.4801823564169308\n",
    "gb 0.48778099198016756\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.) Next, use a <code style=\"color:SteelBlue\">for</code> loop, print the performance of each model in <code style=\"color:SteelBlue\">fitted_models</code> on the test set.\n",
    "* Print both <code style=\"color:SteelBlue\">r2_score</code> and <code style=\"color:SteelBlue\">mean_absolute_error</code>.\n",
    "* Those functions each take two arguments:\n",
    "    * The actual values for your target variable (<code style=\"color:SteelBlue\">y_test</code>)\n",
    "    * Predicted values for your target variable\n",
    "* Label the output with the name of the algorithm. For example:\n",
    "\n",
    "<pre style=\"color:crimson\">\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.409313458932\n",
    "MAE: 84963.5598922\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso\n",
      "---------\n",
      "R2_score: 0.4088862501934907\n",
      "MAE: 85035.54212406879\n",
      "\n",
      "\n",
      "ridge\n",
      "---------\n",
      "R2_score: 0.4093396476329719\n",
      "MAE: 84978.03564808934\n",
      "\n",
      "\n",
      "enet\n",
      "---------\n",
      "R2_score: 0.4052451372948349\n",
      "MAE: 86298.63725401455\n",
      "\n",
      "\n",
      "rf\n",
      "---------\n",
      "R2_score: 0.5698034267683483\n",
      "MAE: 68118.31983914209\n",
      "\n",
      "\n",
      "gb\n",
      "---------\n",
      "R2_score: 0.5400684768585471\n",
      "MAE: 70614.01362199895\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in fitted_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(name)\n",
    "    print(\"---------\")\n",
    "    print(f\"R2_score: {r2_score(y_test, y_pred)}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "\n",
    "<pre>\n",
    "lasso\n",
    "--------\n",
    "R^2: 0.4088862476281637\n",
    "MAE: 85035.54256465772\n",
    "\n",
    "ridge\n",
    "--------\n",
    "R^2: 0.4093396476329718\n",
    "MAE: 84978.03564808934\n",
    "\n",
    "enet\n",
    "--------\n",
    "R^2: 0.4038573361696519\n",
    "MAE: 86529.0068234889\n",
    "\n",
    "rf\n",
    "--------\n",
    "R^2: 0.5712128842598444\n",
    "MAE: 67885.87587131368\n",
    "\n",
    "gb\n",
    "--------\n",
    "R^2: 0.5270040007880257\n",
    "MAE: 71245.11216404787\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Next, ask yourself these questions to pick the winning model:\n",
    "* Which model had the highest $R^2$ on the test set?\n",
    "* Which model had the lowest mean absolute error?\n",
    "* Are these two models the same one?\n",
    "* Did it also have the best holdout $R^2$ score from cross-validation?\n",
    "* Does it satisfy our project's win condition? (**Tip:** In the event of ambiguous results based on the previous questions, THIS should be your final deciding factor on whether a model is \"good enough.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, plot the performance of the winning model on the test set.\n",
    "* Plot a scatterplot with predicted transaction price on the x-axis and actual transaction price on the y-axis.\n",
    "* This last visual check is a nice way to confirm our model's performance.\n",
    "* Are the points scattered around the 45 degree diagonal (what does the 45 degree diagonal line represent)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf_y_pred = fitted_models['rf'].predict(X_test)\n",
    "\n",
    "plt.scatter(rf_y_pred, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<img src=\"data:image/png;base64,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&#10;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:RoyalBlue\">Exercise 5.7 - Saving Your Model</span>\n",
    "\n",
    "Great job, you've created a pretty kick-ass model for real-estate valuation. Now it's time to save your hard work.\n",
    "\n",
    "#### A.) First, display the class of your winning \"model\" in the <code>fitted_models</code> dictionary object.\n",
    "* Remember, you can access it with its corresponding key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.model_selection._search.GridSearchCV'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fitted_models['rf']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.model_selection._search.GridSearchCV\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this is still the <code style=\"color:steelblue\">GridSearchCV</code> class. \n",
    "* You can actually directly save this object if you want, because it will use the winning model pipeline by default. \n",
    "* However, what we really care about is the actual winning model <code style=\"color:steelblue\">Pipeline</code>, right?\n",
    "\n",
    "#### B.) Confirm you can access the winning model pipeline. Display the class of the model pipeline.\n",
    "* **Tip:** You can use its <code style=\"color:steelblue\">best\\_estimator_</code> method to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_pipeline = fitted_models['rf'].best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.pipeline.Pipeline'>\n"
     ]
    }
   ],
   "source": [
    "print(type(best_rf_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "sklearn.pipeline.Pipeline\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C.) Display the winning pipeline object directly. What are the values of the winning values for our hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('standardscaler',\n",
      "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
      "                ('randomforestregressor',\n",
      "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
      "                                       criterion='mse', max_depth=None,\n",
      "                                       max_features='auto', max_leaf_nodes=None,\n",
      "                                       max_samples=None,\n",
      "                                       min_impurity_decrease=0.0,\n",
      "                                       min_impurity_split=None,\n",
      "                                       min_samples_leaf=1, min_samples_split=2,\n",
      "                                       min_weight_fraction_leaf=0.0,\n",
      "                                       n_estimators=200, n_jobs=None,\n",
      "                                       oob_score=False, random_state=123,\n",
      "                                       verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(best_rf_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong style=\"color:RoyalBlue\">Expected output:</strong>\n",
    "<pre>\n",
    "Pipeline(memory=None,\n",
    "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "           oob_score=False, random_state=123, verbose=0, warm_start=False))])\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The winning values for our hyperparameters are:\n",
    "* <code style=\"color:steelblue\">n_estimators: <span style=\"color:crimson\">200</span></code>\n",
    "* <code style=\"color:steelblue\">max_features : <span style=\"color:crimson\">'auto'</span></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D.) Finally, let's save the winning <code style=\"color:steelblue\">Pipeline</code> object object. To do so, we'll import a helpful package called <code style=\"color:steelblue\">pickle</code>, which saves Python objects to disk.\n",
    "* First, <code>import pickle</code>.\n",
    "* Then, use the following syntax to \"dump\" your model into a pickle file.\n",
    "\n",
    "<pre style=\"color:steelblue\">\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(<strong>insert answer to previous question here</strong>, f)\n",
    "</pre>\n",
    "* **Note:** We'll show you in the next project how to take this a step further and use the pickled model for various use cases. For now, we don't want to spread ourselves too thin over too many topics, so let's just save that final model and move on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(fitted_models['rf'].best_estimator_, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations... you've built and saved a successful model trained using machine learning!\n",
    "\n",
    "As a reminder, here are a few things you did in this module:\n",
    "* You split your dataset into separate training and test sets.\n",
    "* You set up preprocessing pipelines.\n",
    "* You tuned your models using cross-validation.\n",
    "* And you evaluated your models, selecting and saving the winner."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
